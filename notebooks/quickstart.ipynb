{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33fd443a",
   "metadata": {},
   "source": [
    "# ðŸš€ ResearchGPT Quickstart\n",
    "\n",
    "This notebook walks through the full pipeline on the sample paper:\n",
    "- Load PDF\n",
    "- Extract metadata\n",
    "- Clean & chunk text\n",
    "- Build index & run search\n",
    "- Summarize & analyze chunks\n",
    "- Save metadata JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- 1) Project root handling ---\n",
    "project_root = Path.cwd().parent  # from notebooks/ â†’ go up one level\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(\"âœ… Project root:\", project_root)\n",
    "\n",
    "# --- 2) Load environment variables ---\n",
    "load_dotenv()\n",
    "print(\"âœ… MISTRAL_API_KEY loaded?\", bool(os.getenv(\"MISTRAL_API_KEY\")))\n",
    "\n",
    "# --- 3) Import local modules ---\n",
    "from src.config import MISTRAL_API_KEY\n",
    "from src.pdf_utils import load_all_pdfs_text\n",
    "from src.text_utils import clean_text, chunk_text\n",
    "from src.indexer import build_index, search\n",
    "from src.summarizer import summarize_chunks\n",
    "from src.analyst import analyze_chunks\n",
    "from src.metadata_utils import extract_metadata\n",
    "from src.io_utils import safe_stem\n",
    "\n",
    "print(\"âœ… Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83260916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the sample paper\n",
    "pdf_path = project_root / \"data/sample_papers/attention_is_all_you_need.pdf\"\n",
    "\n",
    "# Load all PDFs in that folder\n",
    "pairs = load_all_pdfs_text(pdf_path.parent)\n",
    "\n",
    "if not pairs:\n",
    "    raise FileNotFoundError(f\"No PDFs found in {pdf_path.parent.resolve()}\")\n",
    "\n",
    "pdf_path, raw_text = pairs[0]\n",
    "print(\"âœ… Loaded PDF:\", pdf_path.name)\n",
    "print(\"\\n--- First 500 chars of raw text ---\\n\")\n",
    "print(raw_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa2993",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = extract_metadata(pdf_path)\n",
    "\n",
    "print(\"âœ… Metadata extracted:\")\n",
    "print(json.dumps(meta, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "cleaned = clean_text(raw_text)\n",
    "\n",
    "# Chunk text\n",
    "chunks = chunk_text(cleaned, max_chars=1500, overlap=150)\n",
    "\n",
    "print(f\"âœ… Total chunks: {len(chunks)}\")\n",
    "print(\"\\n--- First 2 chunks ---\\n\")\n",
    "for i, ch in enumerate(chunks[:2]):\n",
    "    print(f\"[Chunk {i+1}]\\n{ch[:400]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = build_index([(f\"chunk {i+1}\", ch) for i, ch in enumerate(chunks)])\n",
    "hits = search(index, \"Summarize contributions and limitations.\", k=5)\n",
    "\n",
    "print(\"âœ… Top hits:\")\n",
    "for score, (lbl, txt) in hits:\n",
    "    print(f\"- {lbl} (score={score:.3f})\")\n",
    "    print(txt[:200], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13478f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_chunks = [txt for _s, (_lbl, txt) in hits]\n",
    "\n",
    "summary = summarize_chunks(MISTRAL_API_KEY, \"Attention Is All You Need\", top_chunks)\n",
    "analysis = analyze_chunks(MISTRAL_API_KEY, \"Attention Is All You Need\", top_chunks)\n",
    "\n",
    "print(\"âœ… Summary (first 500 chars):\\n\", summary[:500])\n",
    "print(\"\\n---\\n\")\n",
    "print(\"âœ… Analysis (first 500 chars):\\n\", analysis[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa328b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_out = {\n",
    "    \"file\": pdf_path.name,\n",
    "    \"title\": meta.get(\"title\", pdf_path.stem),\n",
    "    \"authors\": meta.get(\"authors\", \"Unknown\"),\n",
    "    \"abstract\": meta.get(\"abstract\"),\n",
    "    \"query_used\": \"Summarize contributions and limitations.\",\n",
    "    \"outputs\": {\n",
    "        \"summary_md\": str(project_root / \"results/summaries\" / f\"{safe_stem(pdf_path)}_summary.md\"),\n",
    "        \"analysis_md\": str(project_root / \"results/analyses\" / f\"{safe_stem(pdf_path)}_analysis.md\"),\n",
    "    }\n",
    "}\n",
    "\n",
    "meta_dir = project_root / \"results/metadata\"\n",
    "meta_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "meta_path = meta_dir / f\"{safe_stem(pdf_path)}_meta.json\"\n",
    "meta_path.write_text(json.dumps(meta_out, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"âœ… Metadata JSON saved to:\", meta_path)\n",
    "print(json.dumps(meta_out, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
